{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40e26f2c",
   "metadata": {},
   "source": [
    "# ðŸ”„ Customer Churn Prediction (Revised)\n",
    "\n",
    "This notebook predicts whether a telecom customer will churn using demographic and service-related data. It includes:\n",
    "- Data cleaning\n",
    "- Feature selection\n",
    "- Data preparation\n",
    "- Model training with three classifiers\n",
    "- Performance comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0df07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ“¦ Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e8e95a",
   "metadata": {},
   "source": [
    "## ðŸ“‚ Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a154adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"customer_churn.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4664fceb",
   "metadata": {},
   "source": [
    "## ðŸ§¼ Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3379d123",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert TotalCharges to numeric\n",
    "df[\"TotalCharges\"] = pd.to_numeric(df[\"TotalCharges\"], errors=\"coerce\")\n",
    "# Fill missing TotalCharges with median\n",
    "df[\"TotalCharges\"].fillna(df[\"TotalCharges\"].median(), inplace=True)\n",
    "# Check for any remaining nulls\n",
    "df.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da12d9a0",
   "metadata": {},
   "source": [
    "## ðŸ“Š Dataset Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7aea8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9258dc29",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1ebea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data=df, x=\"Churn\")\n",
    "plt.title(\"Churn Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082d390a",
   "metadata": {},
   "source": [
    "## ðŸ§  Feature Selection (Correlation with Churn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5671f4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_corr = df.copy()\n",
    "df_corr[\"Churn\"] = df_corr[\"Churn\"].map({\"Yes\": 1, \"No\": 0})\n",
    "df_encoded = pd.get_dummies(df_corr.drop(columns=\"Churn\"))\n",
    "df_encoded[\"Churn\"] = df_corr[\"Churn\"]\n",
    "correlations = df_encoded.corr()[\"Churn\"].sort_values(ascending=False)\n",
    "correlations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c894f4e4",
   "metadata": {},
   "source": [
    "## ðŸ›  Feature Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce17f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = df.drop(columns=[\"Churn\"])\n",
    "y = df[\"Churn\"].map({\"Yes\": 1, \"No\": 0})\n",
    "\n",
    "numeric_features = [\"tenure\", \"MonthlyCharges\", \"TotalCharges\"]\n",
    "categorical_features = [col for col in X.columns if col not in numeric_features]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a561d8b6",
   "metadata": {},
   "source": [
    "## ðŸ”€ Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b5dfa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba0ce360",
   "metadata": {},
   "source": [
    "## ðŸ§¹ Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65fdc1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"num\", StandardScaler(), numeric_features),\n",
    "    (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), categorical_features)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c798330",
   "metadata": {},
   "source": [
    "## ðŸ¤– Model Training & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab66a53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "models = {\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "}\n",
    "\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    pipe = Pipeline([\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"classifier\", model)\n",
    "    ])\n",
    "    pipe.fit(X_train, y_train)\n",
    "    y_pred = pipe.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    results[name] = acc\n",
    "    print(f\"\\n{name} Accuracy: {acc:.2f}\")\n",
    "    print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d329f22",
   "metadata": {},
   "source": [
    "## ðŸ“ˆ Accuracy Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10c4f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.barplot(x=list(results.keys()), y=list(results.values()))\n",
    "plt.title(\"Model Accuracy Comparison\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.ylim(0, 1)\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
