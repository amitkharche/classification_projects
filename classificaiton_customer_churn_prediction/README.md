

# ğŸ“Š Customer Churn Prediction

A machine learning solution to predict **customer churn** based on service usage and demographic data in the telecom industry. This enables businesses to **retain customers** through proactive interventions.

---

## ğŸ’¼ Business Objective

Churn refers to when a customer stops using a companyâ€™s services. Predicting churn early helps telecom companies:

- Reduce revenue loss  
- Improve customer satisfaction  
- Target high-risk customers with personalized offers  

This project builds a machine learning pipeline that classifies whether a customer is likely to churn or not.

---

## ğŸ§¾ Dataset Overview

The dataset contains information such as:

- **Demographics** (e.g., gender, senior citizen status)
- **Service details** (e.g., internet, phone, contract)
- **Billing information** (e.g., monthly & total charges)

The target variable is **Churn** (`Yes` or `No`), converted to binary values (`1` for churn, `0` for retention).

---

## ğŸ” Features Used

| Category         | Features                                                                 |
|------------------|--------------------------------------------------------------------------|
| **Demographics** | `gender`, `SeniorCitizen`, `Partner`, `Dependents`                      |
| **Services**     | `PhoneService`, `MultipleLines`, `InternetService`, `OnlineSecurity`, etc. |
| **Billing**      | `MonthlyCharges`, `TotalCharges`, `tenure`                              |

---

## ğŸ§  Models Implemented

Three classification models are trained using a unified preprocessing pipeline:

- ğŸ¯ **Random Forest**
- ğŸ”¢ **Logistic Regression**
- âš¡ **XGBoost**

Each model is trained using a **scikit-learn `Pipeline`** to ensure standardized preprocessing and reproducibility.

---

## âš™ï¸ Project Structure

\`\`\`
â”œâ”€â”€ churn_features.pkl                 # List of input features used during training
â”œâ”€â”€ customer_churn.csv                # Input dataset
â”œâ”€â”€ logisticregression_churn_model.pkl # Trained Logistic Regression model
â”œâ”€â”€ randomforest_churn_model.pkl      # Trained Random Forest model
â”œâ”€â”€ xgboost_churn_model.pkl           # Trained XGBoost model
â”œâ”€â”€ model_training.py                 # Python script to train and save models
â”œâ”€â”€ app.py                            # Streamlit app (optional for deployment)
â”œâ”€â”€ requirements.txt                  # Python dependencies
â””â”€â”€ README.md                         # Project documentation
\`\`\`

---

## ğŸ—ï¸ Pipeline Steps

### 1. **Data Cleaning**

- Convert `TotalCharges` to numeric
- Impute missing `TotalCharges` values using median

### 2. **Feature Engineering**

- Separate into **numerical** and **categorical** features
- Scale numerical features using `StandardScaler`
- Encode categorical features using `OneHotEncoder`

### 3. **Model Training**

Each model is wrapped in a scikit-learn `Pipeline` to include preprocessing and training:

\`\`\`python
Pipeline([
    ("preprocessor", ColumnTransformer([
        ("num", StandardScaler(), numeric_features),
        ("cat", OneHotEncoder(handle_unknown="ignore"), categorical_features)
    ])),
    ("classifier", model)
])
\`\`\`

### 4. **Model Saving**

All models are saved as `.pkl` files using `joblib`.

---

## ğŸš€ How to Run the Project

### ğŸ”§ Step 1: Install Dependencies

\`\`\`bash
pip install -r requirements.txt
\`\`\`

### ğŸ“ˆ Step 2: Train Models

\`\`\`bash
python model_training.py
\`\`\`

This will generate:
- `randomforest_churn_model.pkl`
- `logisticregression_churn_model.pkl`
- `xgboost_churn_model.pkl`
- `churn_features.pkl`

### ğŸ–¥ï¸ Step 3: Run Streamlit App (Optional)

\`\`\`bash
streamlit run app.py
\`\`\`

This will launch a browser-based UI for making churn predictions interactively.

---

## ğŸ› ï¸ Requirements

Below are the main dependencies:

\`\`\`text
pandas
scikit-learn
xgboost
joblib
streamlit
\`\`\`

*(Full list in \`requirements.txt\`)*

---

## ğŸ“Š Future Enhancements

- Add SHAP-based model explainability
- Model performance comparison dashboard
- Integration with real-time data sources via FastAPI or Flask
- Add evaluation metrics like ROC AUC, precision, recall

---

## ğŸ™Œ Acknowledgements

- [IBM Telco Customer Churn Dataset](https://www.kaggle.com/blastchar/telco-customer-churn)
- Built using Python, scikit-learn, and XGBoost

---

## ğŸ“¬ Contact

If you have questions or want to collaborate, feel free to connect with me on [LinkedIn](https://linkedin.com).
